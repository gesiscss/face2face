{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic tutorial about pandas\n",
    "\n",
    "**Author**: Andreas Kruff\n",
    "\n",
    "**Version**: 20.04.2020\n",
    "\n",
    "**Description**: This tutorial should give you an idea about the functions from pandas that are used in this library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple options to import a data set. For this tutorial we use the <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\">read_csv</a> function from pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now as a first step try to import the TIJ data set of WS16 with the read_csv function of pandas. The path directory you can use is \"../data/WS16/tij_WS16.dat\" and after that use print() to create an output of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/WS16/tij_WS16.dat\", sep=\"\\t\", header=None, engine='python', index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This kind of datasets are usually pretty big with lots of rows and columns. To get an overview use the <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html\">head</a> function to reduce the output of print() to 25 rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of head() you can also use <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.tail.html?highlight=tail#pandas.DataFrame.tail\">tail()</a> to get the last entries of a dataset or you use <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sample.html?highlight=sample#pandas.DataFrame.sample\">sample()</a> to get an amount of random rows from the datasets. Play around with this functions if you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better access to specific columns in the dataset its good to use meaningful column names. If you haven't done it yet use the <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rename.html?highlight=rename#pandas.DataFrame.rename\">rename()</a> function to give column names. For this dataset i recommend you to use \"Time\", \"i\" and \"j\" as column names for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={0: \"Time\", 1: \"i\", 2: \"j\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have prepared our tij dataset, we can play around with the dataset. For example we could sort the dataset by the persons contact. Try to use <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_values.html?highlight=sort_values#pandas.DataFrame.sort_values\">sort_values</a> for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df.sort_values(by=[\"i\", \"j\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to know for how long people have talked to each other you can use the function <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html?highlight=groupby#pandas.DataFrame.groupby\">groupby</a> and group the datasets by all combinations of i and j. On top of that you can use the <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.DataFrameGroupBy.diff.html?highlight=diff#pandas.core.groupby.DataFrameGroupBy.diff\">diff()</a> function to get the differences between \"Time\" in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Time  i   j     diff\n",
      "107076  1480583020  0  26      NaN\n",
      "124647  1480589960  1   0      NaN\n",
      "136534  1480592120  1   0   2160.0\n",
      "2519    1480489180  1   2      NaN\n",
      "22905   1480501800  1   2  12620.0\n"
     ]
    }
   ],
   "source": [
    "df_sorted[\"diff\"] = df_sorted.groupby([\"i\", \"j\"])[\"Time\"].diff()\n",
    "print(df_sorted.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you probably know for the measurements of this dataset they used RFID Chips which exchangend packages if people stand close in front of each other. If a full package could be delivered it means that people talked at least 20 sec with each other and than the RFID restarts their exchange. That explains why there so many values of 20, because the involved people kept talking. If the difference is higher than 20 it means there was a break in the conversation. If the value is \"NaN\" it means its the first contact of this two persons in this dataset, but this entry also says they talked for 20 seconds already."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So with this tools you can already analyze how long people talked with each other and this is also the basis of the distribution methods of the face2face library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a deeper understanding of human interaction and which attributes are decisive for their behaviour we have to include the collected metadata as well. For this use the read_csv function again to import the metadata of \"WS16\". (\"../data/WS16/metadata_WS16.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = pd.read_csv(\"../data/WS16/metadata_WS16.dat\", sep=\"\\t\", header=None, engine='python', index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see this dataframe doesn't have column names either. So in this case you can check the README file for the interpretation of the data and after that you can use the rename() function again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = df_meta.rename(columns={0: \"ID\", 1: \"Age\", 2: \"Sex\", 3: \"Country\",\n",
    "                                                                  4: \"Language\", 5: \"Education\",\n",
    "                                                                  6: \"Academic Background\", 7: \"Role\",\n",
    "                                                                  8: \"Previous participation\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see now the metadata has a column named \"ID\" and the tij-dataset has also corresponding ID's to that in the columns i and j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137}\n"
     ]
    }
   ],
   "source": [
    "distinct_IDs = set(df_sorted[\"i\"])\n",
    "print(distinct_IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137}\n"
     ]
    }
   ],
   "source": [
    "distinct_IDs = set(df_sorted[\"j\"])\n",
    "print(distinct_IDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a look at the column \"ID\" of the metadata this lists are pretty much similar. If some ID's are missing in the tij data it means that they had no conversations or the RFID chip did not work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we now want to combine the two datasets to analyze the behaviour based on attributes we can use the <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html?highlight=merge#pandas.DataFrame.merge\">merge</a>\n",
    "function. This function allows us to attach the metadata to the fitting ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Time    i    j  ID_x  Age_x Sex_x Country_x Language_x  Education_x  \\\n",
      "0  1480486100  125  130   125    0.0     M        C1      Other          2.0   \n",
      "1  1480486100    7  130     7    0.0     F        C1         L2          2.0   \n",
      "2  1480486100    9  110     9    1.0     M        C1         L1          3.0   \n",
      "3  1480486120    9  130     9    1.0     M        C1         L1          3.0   \n",
      "4  1480486160  125  130   125    0.0     M        C1      Other          2.0   \n",
      "\n",
      "   Academic Background_x  ...  Previous participation_x ID_y  Age_y  Sex_y  \\\n",
      "0                    2.0  ...                       Yes  130    0.0      M   \n",
      "1                    1.0  ...                       Yes  130    0.0      M   \n",
      "2                    2.0  ...                       Yes  110    1.0      F   \n",
      "3                    2.0  ...                       Yes  130    0.0      M   \n",
      "4                    2.0  ...                       Yes  130    0.0      M   \n",
      "\n",
      "  Country_y Language_y Education_y  Academic Background_y  Role_y  \\\n",
      "0        C1      Other         3.0                    3.0     4.0   \n",
      "1        C1      Other         3.0                    3.0     4.0   \n",
      "2        C1        NaN         1.0                    2.0     4.0   \n",
      "3        C1      Other         3.0                    3.0     4.0   \n",
      "4        C1      Other         3.0                    3.0     4.0   \n",
      "\n",
      "   Previous participation_y  \n",
      "0                        No  \n",
      "1                        No  \n",
      "2                       Yes  \n",
      "3                        No  \n",
      "4                        No  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "df_merge_meta_1 = df.merge(df_meta, how=\"left\", left_on=\"i\", right_on=\"ID\")\n",
    "df_merge_meta = df_merge_meta_1.merge(df_meta, how=\"left\", left_on=\"j\", right_on=\"ID\")\n",
    "print(df_merge_meta.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see now we have the metadata informations for both persons of every contact in the same row now and we can use that for example in the average_degree method to check if their are correlations in the communicativity between an attribute and the degree of this person."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
